{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the dataset\n",
    "\n",
    "\n",
    "In this notebook, we will perform an EDA (Exploratory Data Analysis) on the processed Waymo dataset (data in the `processed` folder). In the first part, you will create a function to display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_dataset\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading unweighted datasets: ['./data/**/*.tfrecord']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['./data/**/*.tfrecord']\n",
      "INFO:tensorflow:Number of filenames to read: 99\n",
      "WARNING:tensorflow:From /data/virtual_envs/sdc-c1-gpu-augment/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /data/virtual_envs/sdc-c1-gpu-augment/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n"
     ]
    }
   ],
   "source": [
    "# dataset = get_dataset(\"/home/workspace/data/waymo/training_and_validation/*.tfrecord\")\n",
    "# Running Sourcery on changed code, grouping rules, better login, and more\n",
    "\n",
    "# tfrecord_path = \"/home/workspace/data/waymo/training_and_validation/*.tfrecord\"\n",
    "# tfrecord_path = \"./data/train/*.tfrecord\"\n",
    "tfrecord_path = \"./data/**/*.tfrecord\"\n",
    "dataset = get_dataset(tfrecord_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function to display an image and the bounding boxes\n",
    "\n",
    "Implement the `display_images` function below. This function takes a batch as an input and display an image with its corresponding bounding boxes. The only requirement is that the classes should be color coded (eg, vehicles in red, pedestrians in blue, cyclist in green)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(batch):\n",
    "    # TODO - Your implementation here\n",
    "    # pass\n",
    "   \n",
    "    img = batch['image'].numpy()\n",
    "    img_h, img_w, _ = img.shape\n",
    "   \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20, 20))\n",
    "    ax.imshow(img)\n",
    "   \n",
    "    bboxes = batch['groundtruth_boxes'].numpy()\n",
    "    # to rectangle pixel coordinates\n",
    "    bboxes[:, (0, 2)] *= img_h\n",
    "    bboxes[:, (1, 3)] *= img_w\n",
    "   \n",
    "    # color mapping of classes: (vehicles red, pedestrians blue, cyclists green)\n",
    "    colormap = {1:[1, 0, 0], 2:[0, 0, 1], 3:[0, 1, 0]}\n",
    "    classes = batch['groundtruth_classes'].numpy()\n",
    "   \n",
    "    for bbox, classe in zip(bboxes, classes):\n",
    "        y1, x1, y2, x2 = bbox\n",
    "        try:\n",
    "            rec = patches.Rectangle((x1, y1), (x2 - x1), (y2 - y1), edgecolor = colormap[classe], facecolor='none')\n",
    "            ax.add_patch(rec)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "   \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display 10 images \n",
    "\n",
    "Using the dataset created in the second cell and the function you just coded, display 10 random images with the associated bounding boxes. You can use the methods `take` and `shuffle` on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 10 random images in dataset\n",
    "dataset = dataset.shuffle(100)\n",
    "\n",
    "for idx, batch in enumerate(dataset.take(10)):\n",
    "    display_images(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional EDA\n",
    "\n",
    "In this last part, you are free to perform any additional analysis of the dataset. What else would like to know about the data?\n",
    "For example, think about data distribution. So far, you have only looked at a single file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_total = []\n",
    "# count_batch_reset = {1:0, 2:0, 4:0}\n",
    "count_batch = {1:0, 2:0, 4:0}\n",
    "label = ['vehicle', 'pedestrian', 'cyclist']\n",
    "colormap = [[1, 0, 0], [0, 0, 1], [0, 1, 0]]\n",
    "without_bbox = 0\n",
    "\n",
    "dataset = dataset.take(50)\n",
    "\n",
    "for i, batch in enumerate(dataset):\n",
    "    # count_batch = count_batch_reset\n",
    "    count_batch = {1:0, 2:0, 4:0}\n",
    "    classes = batch['groundtruth_classes'].numpy()\n",
    "   \n",
    "    for idx in classes:\n",
    "        count_batch[idx] += 1\n",
    "        if np.all((classes == 0)):\n",
    "            without_bbox += 1\n",
    "    count_total.append(list(count_batch.values()))\n",
    "   \n",
    "summ = np.sum((count_total), axis=1)\n",
    "\n",
    "print(f'Total of bounding boxes: {np.sum(summ)}')\n",
    "print(f'Bbox Distribution among images: {dict(enumerate(summ.flatten()))}\\n')\n",
    "\n",
    "lst = []\n",
    "for i in range (len(summ)):\n",
    "    lst.append('img_' + str(i))\n",
    "\n",
    "cl_distr = np.sum((count_total), axis=0)\n",
    "print(f'Class Distribution: {cl_distr[0]} {label[0]}, {cl_distr[1]} {label[1]}, and {cl_distr[2]} {label[2]}')\n",
    "\n",
    "count_total = np.array(count_total)\n",
    "\n",
    "mean = np.mean((count_total), axis=0)\n",
    "print(f'Class Mean per image: {mean[0]} {label[0]}, {mean[1]} {label[1]}, {mean[2]} {label[2]}')\n",
    "\n",
    "sdev = np.std((count_total), axis=0)\n",
    "print(f'Class Std Deviation per image: {sdev[0]} {label[0]}, {sdev[1]} {label[1]}, {sdev[2]} {label[2]}')\n",
    "print('')\n",
    "print(f'Number of images without bounding boxes: {without_bbox}')\n",
    "\n",
    "fig2, ax2 = plt.subplots(1, 3, figsize=(18, 6))\n",
    "ax2[0].bar(label, cl_distr, align='center', alpha=0.5, color=colormap)\n",
    "ax2[0].set(ylabel = 'Number of Bounding Boxes')\n",
    "ax2[0].set_title('Class Distribution')\n",
    "\n",
    "count_veh = count_total[:, 0]\n",
    "count_ped = count_total[:, 1]\n",
    "count_bic = count_total[:, 2]\n",
    "bike = np.sum((count_veh, count_ped), axis=0)\n",
    "ax2[1].bar(lst, count_veh, align='center', alpha=0.5, color='red')\n",
    "ax2[1].bar(lst, count_ped, align='center', alpha=0.5, color='blue', bottom=count_veh)\n",
    "ax2[1].bar(lst, count_bic, align='center', alpha=0.5, color='green', bottom=bike)\n",
    "ax2[1].set_title('Bbox Distribution')\n",
    "ax2[1].set(ylabel='Number of Bounding Boxes', xlabel='Sequential Images from 1 at√© 50')\n",
    "\n",
    "bins = []\n",
    "for i in range(0, 100 + 1, 5):\n",
    "    bins.append(i)\n",
    "ax2[2].hist(summ, bins=bins, orientation='horizontal', alpha=0.5, color='orange')\n",
    "ax2[2].set_title('Bbox Histogram')\n",
    "ax2[2].set(ylabel='Number of Bounding Boxes', xlabel='Number of Images')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
